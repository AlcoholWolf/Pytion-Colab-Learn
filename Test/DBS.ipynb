{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DBS.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNnpbMzv092Xu1f4IHqXmjP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlcoholWolf/Pytion-Colab-Learn/blob/main/Test/DBS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DACON Boice"
      ],
      "metadata": {
        "id": "IJ-pMLTtbR3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import"
      ],
      "metadata": {
        "id": "cve63jHsbNMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AlcoholWolf/SDASSF\n",
        "import sys\n",
        "sys.path.append('./SDASSF/Prossece')\n",
        "from GetAll import *"
      ],
      "metadata": {
        "id": "lGVPSjNAPqKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA"
      ],
      "metadata": {
        "id": "1FGp1aCGbLNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/u/0/uc?id=1kwyxHwhzi9kh9YcV_0a-oqeYUQmrRmtj&export=download"
      ],
      "metadata": {
        "id": "o28am7X2bygC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir dacon"
      ],
      "metadata": {
        "id": "46bOhUUAeSyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/open.zip -d /content/dacon"
      ],
      "metadata": {
        "id": "7_H94GfKdIYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission = pd.read_csv(\"/content/dacon/sample_submission.csv\")\n",
        "\n",
        "africa_train_paths = glob(\"/content/dacon/train/africa/*.wav\")\n",
        "australia_train_paths = glob(\"/content/dacon/train/australia/*.wav\")\n",
        "canada_train_paths = glob(\"/content/dacon/train/canada/*.wav\")\n",
        "england_train_paths = glob(\"/content/dacon/train/england/*.wav\")\n",
        "hongkong_train_paths = glob(\"/content/dacon/train/hongkong/*.wav\")\n",
        "us_train_paths = glob(\"/content/dacon/train/us/*.wav\")\n",
        "\n",
        "path_list = [africa_train_paths, australia_train_paths, canada_train_paths,\n",
        "             england_train_paths, hongkong_train_paths, us_train_paths]"
      ],
      "metadata": {
        "id": "lowjpFJXbGDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glob(\"/content/dacon/test/*.wav\")"
      ],
      "metadata": {
        "id": "ik8IHTtBjPaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_id(data):\n",
        "    return np.int(data.split(\"/content/dacon/test/\")[1].split(\".\")[0])\n",
        "\n",
        "test_ = pd.DataFrame(index = range(0, 6100), columns = [\"path\", \"id\"])\n",
        "test_[\"path\"] = glob(\"/content/dacon/test/*.wav\")\n",
        "test_[\"id\"] = test_[\"path\"].apply(lambda x : get_id(x))\n",
        "\n",
        "test_.head()"
      ],
      "metadata": {
        "id": "nP9w5NkqijWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data_Loader"
      ],
      "metadata": {
        "id": "wj9URa6ikaFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(paths):\n",
        "\n",
        "    result = []\n",
        "    for path in tqdm(paths):\n",
        "\n",
        "        data, sr = librosa.load(path, sr = 16000)\n",
        "        result.append(data)\n",
        "    result = np.array(result) \n",
        "\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "a6qliDIqkvAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir(\"./npy_data\")\n",
        "\n",
        "africa_train_data = load_data(africa_train_paths)\n",
        "np.save(\"./npy_data/africa_npy\", africa_train_data)\n",
        "\n",
        "australia_train_data = load_data(australia_train_paths)\n",
        "np.save(\"./npy_data/australia_npy\", australia_train_data)\n",
        "\n",
        "canada_train_data = load_data(canada_train_paths)\n",
        "np.save(\"./npy_data/canada_npy\", canada_train_data)\n",
        "\n",
        "england_train_data = load_data(england_train_paths)\n",
        "np.save(\"./npy_data/england_npy\", england_train_data)\n",
        "\n",
        "hongkong_train_data = load_data(hongkong_train_paths)\n",
        "np.save(\"./npy_data/hongkong_npy\", hongkong_train_data)\n",
        "\n",
        "us_train_data = load_data(us_train_paths)\n",
        "np.save(\"./npy_data/us_npy\", us_train_data)\n",
        "\n",
        "test_data = load_data(test_[\"path\"])\n",
        "np.save(\"./npy_data/test_npy\", test_data)"
      ],
      "metadata": {
        "id": "cyZvJADbkxdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "africa_train_data = np.load(\"./npy_data/africa_npy.npy\", allow_pickle = True)\n",
        "australia_train_data = np.load(\"./npy_data/australia_npy.npy\", allow_pickle = True)\n",
        "canada_train_data = np.load(\"./npy_data/canada_npy.npy\", allow_pickle = True)\n",
        "england_train_data = np.load(\"./npy_data/england_npy.npy\", allow_pickle = True)\n",
        "hongkong_train_data = np.load(\"./npy_data/hongkong_npy.npy\", allow_pickle = True)\n",
        "us_train_data = np.load(\"./npy_data/us_npy.npy\", allow_pickle = True)\n",
        "\n",
        "test_data = np.load(\"./npy_data/test_npy.npy\", allow_pickle = True)\n",
        "\n",
        "train_data_list = [africa_train_data, australia_train_data, canada_train_data, england_train_data, hongkong_train_data, us_train_data]"
      ],
      "metadata": {
        "id": "XTK_V3T-k0CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mini(data):\n",
        "\n",
        "    mini = 9999999\n",
        "    for i in data:\n",
        "        if len(i) < mini:\n",
        "            mini = len(i)\n",
        "\n",
        "    return mini\n",
        "\n",
        "\n",
        "def set_length(data, d_mini):\n",
        "\n",
        "    result = []\n",
        "    for i in data:\n",
        "        result.append(i[:d_mini])\n",
        "    result = np.array(result)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_feature(data, sr = 16000, n_fft = 256, win_length = 200, hop_length = 160, n_mels = 64):\n",
        "    mel = []\n",
        "    for i in data:\n",
        "        mel_ = librosa.feature.melspectrogram(i, sr = sr, n_fft = n_fft, win_length = win_length, hop_length = hop_length, n_mels = n_mels)\n",
        "        mel.append(mel_)\n",
        "    mel = np.array(mel)\n",
        "    mel = librosa.power_to_db(mel, ref = np.max)\n",
        "\n",
        "    mel_mean = mel.mean()\n",
        "    mel_std = mel.std()\n",
        "    mel = (mel - mel_mean) / mel_std\n",
        "\n",
        "    return mel"
      ],
      "metadata": {
        "id": "Je3LOOpVk11A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = np.concatenate(train_data_list, axis= 0)\n",
        "test_x = np.array(test_data)\n",
        "\n",
        "\n",
        "train_mini = get_mini(train_x)\n",
        "test_mini = get_mini(test_x)\n",
        "\n",
        "mini = np.min([train_mini, test_mini])\n",
        "\n",
        "\n",
        "train_x = set_length(train_x, mini)\n",
        "test_x = set_length(test_x, mini)\n",
        "\n",
        "\n",
        "train_x = get_feature(data = train_x)\n",
        "test_x = get_feature(data = test_x)\n",
        "\n",
        "train_x = train_x.reshape(-1, train_x.shape[1], train_x.shape[2], 1)\n",
        "test_x = test_x.reshape(-1, test_x.shape[1], test_x.shape[2], 1)"
      ],
      "metadata": {
        "id": "ejGF12_Uk4N4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = np.concatenate((np.zeros(len(africa_train_data), dtype = np.int),\n",
        "                        np.ones(len(australia_train_data), dtype = np.int),\n",
        "                         np.ones(len(canada_train_data), dtype = np.int) * 2,\n",
        "                         np.ones(len(england_train_data), dtype = np.int) * 3,\n",
        "                         np.ones(len(hongkong_train_data), dtype = np.int) * 4,\n",
        "                         np.ones(len(us_train_data), dtype = np.int) * 5), axis = 0)"
      ],
      "metadata": {
        "id": "XaLe07lOk6ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T_List = [train_x, train_y, test_x]\n",
        "ShapeBuilder(T_List)"
      ],
      "metadata": {
        "id": "Fn6rHsj4k8Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "GMvgAKarbGWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (Input, Convolution2D, BatchNormalization, Flatten,\n",
        "                                     Dropout, Dense, AveragePooling2D, Add)\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "oMrVSMLuU8AN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def block(input_, units = 32, dropout_rate = 0.5):\n",
        "    \n",
        "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(input_)\n",
        "    x = BatchNormalization()(x)\n",
        "    x_res = x\n",
        "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Add()([x, x_res])\n",
        "    x = AveragePooling2D()(x)\n",
        "    x = Dropout(rate=dropout_rate)(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "def second_block(input_, units = 64, dropout_rate = 0.5):\n",
        "    \n",
        "    x = Convolution2D(units, 1, padding =\"same\", activation = \"relu\")(input_)\n",
        "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
        "    x = Convolution2D(units * 4, 1, padding =\"same\", activation = \"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x_res = x\n",
        "    x = Convolution2D(units, 1, padding =\"same\", activation = \"relu\")(x)\n",
        "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
        "    x = Convolution2D(units * 4, 1, padding =\"same\", activation = \"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Convolution2D(units, 1, padding = \"same\", activation = \"relu\")(x)\n",
        "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
        "    x = Convolution2D(units * 4, 1, padding = \"same\", activation = \"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Add()([x, x_res])\n",
        "    x = AveragePooling2D()(x)\n",
        "    x = Dropout(rate=dropout_rate)(x)\n",
        "    \n",
        "    return x"
      ],
      "metadata": {
        "id": "Eiy3L2EYaxPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_fn():\n",
        "    dropout_rate = 0.3\n",
        "    \n",
        "    in_ = Input(shape = (train_x.shape[1:]))\n",
        "    \n",
        "    block_01 = block(in_, units = 32, dropout_rate = dropout_rate)\n",
        "    block_02 = block(block_01, units = 64, dropout_rate = dropout_rate)\n",
        "    block_03 = block(block_02, units = 128, dropout_rate = dropout_rate)\n",
        "\n",
        "    block_04 = second_block(block_03, units = 64, dropout_rate = dropout_rate)\n",
        "    block_05 = second_block(block_04, units = 128, dropout_rate = dropout_rate)\n",
        "\n",
        "    x = Flatten()(block_05)\n",
        "\n",
        "    x = Dense(units = 128, activation = \"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x_res = x\n",
        "    x = Dropout(rate = dropout_rate)(x)\n",
        "\n",
        "    x = Dense(units = 128, activation = \"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Add()([x_res, x])\n",
        "    x = Dropout(rate = dropout_rate)(x)\n",
        "\n",
        "    model_out = Dense(units = 6, activation = 'softmax')(x)\n",
        "    model = Model(in_, model_out)\n",
        "    return model"
      ],
      "metadata": {
        "id": "V5Ic8EV4a2JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 10)\n",
        "\n",
        "pred = []\n",
        "pred_ = []\n",
        "\n",
        "for train_idx, val_idx in split.split(train_x, train_y):\n",
        "    x_train, y_train = train_x[train_idx], train_y[train_idx]\n",
        "    x_val, y_val = train_x[val_idx], train_y[val_idx]\n",
        "\n",
        "    model = build_fn()\n",
        "    model.compile(optimizer = keras.optimizers.Adam(0.002),\n",
        "                 loss = keras.losses.SparseCategoricalCrossentropy(),\n",
        "                 metrics = ['acc'])\n",
        "\n",
        "    history = model.fit(x = x_train, y = y_train, validation_data = (x_val, y_val), epochs = 8)\n",
        "    print(\"*******************************************************************\")\n",
        "    pred.append(model.predict(test_x))\n",
        "    pred_.append(np.argmax(model.predict(test_x), axis = 1))\n",
        "    print(\"*******************************************************************\")"
      ],
      "metadata": {
        "id": "HVHJvBqPa9vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cov_type(data):\n",
        "    return np.int(data)\n",
        "\n",
        "result = pd.concat([test_, pd.DataFrame(np.mean(pred, axis = 0))], axis = 1).iloc[:, 1:]\n",
        "result[\"id\"] = result[\"id\"].apply(lambda x : cov_type(x))\n",
        "\n",
        "result = pd.merge(sample_submission[\"id\"], result)\n",
        "result.columns = sample_submission.columns"
      ],
      "metadata": {
        "id": "JPithgZDbAfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "WBLOF21sCOJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.to_csv(\"DACON.csv\", index = False)"
      ],
      "metadata": {
        "id": "7awJ6UIACQWh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}